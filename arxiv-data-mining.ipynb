{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analyse von Arxiv: Strukturierte und unstrukturierte Daten\n",
    "\n",
    "Dieses Jupyter Notebook stellt die Prüfungsaufgabe des Moduls \"Maschinelles Lernen\" (ROB60) der Akad University dar.\n",
    "\n",
    "## Einführung\n",
    "\n",
    "Die Aufgabenstellung dieser Prüfung ist es Artikel zu einem selbstgewählten Thema der Webseite [Arxiv](https://arxiv.org/) zu analysieren.\n",
    "Im ersten Schritt wird ein Histogramm der über die Anzahl der Artikel pro Autor erstellt. Im Weiteren wird eine deskriptive Analyse für die verschiedenen Jahr durchgeführt.\n",
    "Das Ziel ist zu eruieren, ob sich über die Jahre gewisse Parameter oder Korrelationen verändert haben. Dies könnte beispielsweise die Anzahl der veröffentlichten Artikel pro Autor\n",
    "oder die Anzahl an Autoren sein. Darüber hinaus wird eine Textanalyse durchgeführt. Diese Analyse wird anhand des Abstracts der Artikel durchgeführt.\n",
    "Diese Aufgaben werden sich am CRISP DM Standard orientieren und die folgenden Punkte beinhalten:\n",
    "\n",
    "1. Verstehen der Daten\n",
    "2. Datenvorbereitung\n",
    "3. Modellierung\n",
    "4. Auswertung\n",
    "\n",
    "## Extraktion der Daten von Arxiv\n",
    "\n",
    "Für die Extraktion der Daten findet mittels der Web-API der Platform von Arxiv statt. Es wird das exemplarische Stichwort \"Deep Reinforcement Learning\" gewählt.\n",
    "Um eine möglichst aussagekräftige Analyse durchführen zu können, werden Artikel für die Jahre 2017-2021 heruntergeladen. Pro Jahr sollen 200 Artikel heruntergeladen und in die\n",
    "Analyse miteinbezogen werden."
   ],
   "id": "3eaccebc836882e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import arxiv\n",
    "import pandas as pd\n",
    "from arxiv import SortCriterion, Search\n",
    "\n",
    "# Define number of articles and search query\n",
    "number_of_articles = 200\n",
    "search_query = f\"Deep Reinforcement Learning AND submittedDate:[{2018}01010000 TO {2018}12312359]\"\n",
    "\n",
    "# Generate the client\n",
    "client = arxiv.Client()\n",
    "\n",
    "# Search for the articles\n",
    "search = Search(\n",
    "    query=search_query,\n",
    "    max_results=number_of_articles,\n",
    "    sort_by=SortCriterion.SubmittedDate,\n",
    ")\n",
    "\n",
    "results = client.results(search)\n",
    "\n",
    "# Save retrieved data in array\n",
    "articles = []\n",
    "for result in results:\n",
    "    article = {\n",
    "        \"Title\": result.title,\n",
    "        \"Authors\": result.authors,\n",
    "        \"Abstract\": result.summary,\n",
    "        \"PublishedDate\": result.published,\n",
    "    }\n",
    "    articles.append(article)\n",
    "\n",
    "# Save articles in data frame\n",
    "df = pd.DataFrame(articles)\n",
    "print(df.head())"
   ],
   "id": "eab8a0410836482f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
